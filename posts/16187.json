{"bookmarked": 6, "bucket_name": "Today", "bucket_order": 3, "change_log": [{"anon": "stud", "data": "kwv3r9a3viu1en", "type": "create", "uid_a": "a_0", "v": "all", "when": "2021-12-06T20:04:38Z"}, {"anon": "no", "data": "kwvqkkaux7e1fu", "to": "kwv3r9a01a61em", "type": "s_answer", "uid": "jktvhgjq1t661g", "when": "2021-12-07T06:43:17Z"}], "children": [{"bucket_name": "Today", "bucket_order": 3, "children": [], "config": {"editor": "md"}, "created": "2021-12-07T06:43:17Z", "data": {"embed_links": []}, "folders": [], "history": [{"anon": "no", "content": "<md>Mem len looks like it controls the number previous tokens are cached as an input to generate the next input. Obviously if you increase this number, each forward pass of the network will have more inputs and attention and take more compute and time to run.</md>", "created": "2021-12-07T06:43:17Z", "subject": "", "uid": "jktvhgjq1t661g"}], "history_size": 1, "id": "kwvqkkalwt31fs", "is_tag_endorse": false, "tag_endorse": [{"admin": false, "endorser": {"jzllv02dp7j3jh": 1571985065, "kdhvjzdceb91ll": 1607826884}, "facebook_id": null, "id": "jktvg5rtq4e4uz", "name": "Jay Monga", "photo": "1580804937_200.jpg", "photo_url": "https://cdn-uploads.piazza.com/photos/jktvg5rtq4e4uz/1580804937_200.jpg", "published": true, "role": "student", "us": false}], "tag_endorse_arr": ["jktvg5rtq4e4uz"], "type": "s_answer"}], "config": {"editor": "rte", "has_emails_sent": 1, "seen": {"11703": 7, "13220": 8, "15949": 0, "1882": 2, "3333": 9, "3982": 4, "4434": 1, "4485": 3, "602": 5, "6788": 6}}, "created": "2021-12-06T20:04:38Z", "data": {"embed_links": []}, "default_anonymity": "no", "drafts": null, "folders": ["eecs", "suggestion_box", "research"], "history": [{"anon": "stud", "content": "<p>In Transformer-XL, we cache all previous tokens so that the next token generation is faster. However, when I change the arg\u00a0<kbd>mem_len</kbd> from 0 to 128, the runtime significantly increased.</p>\n<p></p>\n<p>Could any big ballers tell me why this happens and how to replicate the correct experiments for baseline?</p>\n<p></p>\n<p><img src=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fk8gqq79bey01ts%2F2ce844d812dff1ea723ea2bb9f0b13c6893fa4ff0e697d04619fb6f7b606c478%2FScreen_Shot_2021-12-06_at_11.49.07.png\" alt=\"Screen_Shot_2021-12-06_at_11.49.07.png\" width=\"1000\" /><img src=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fk8gqq79bey01ts%2F2dac67099a3fdeb874ad729450f10c126f32367e442faeeffda0e20d45096a9e%2FScreen_Shot_2021-12-06_at_11.49.14.png\" alt=\"Screen_Shot_2021-12-06_at_11.49.14.png\" width=\"1000\" /></p>", "created": "2021-12-06T20:04:38Z", "subject": "transformer-xl experiments opposite of expectation", "uid_a": "a_0"}], "history_size": 1, "i_edits": [], "id": "kwv3r9a01a61em", "is_bookmarked": false, "is_tag_good": false, "my_favorite": false, "no_answer": 0, "no_answer_followup": 0, "nr": 16187, "num_favorites": 0, "q_edits": [], "request_instructor": 0, "request_instructor_me": false, "s_edits": [], "status": "active", "t": 1654539191320, "tag_good": [], "tag_good_arr": [], "tags": ["eecs", "research", "student", "suggestion_box"], "type": "question", "unique_views": 287}