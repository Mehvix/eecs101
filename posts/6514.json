{"bookmarked": 5, "bucket_name": "Today", "bucket_order": 3, "change_log": [{"anon": "stud", "data": "jfooun6cbb492", "type": "create", "uid_a": "a_0", "when": "2018-04-07T01:16:21Z"}, {"anon": "stud", "data": "jfoovxd3mpu10w", "type": "update", "uid_a": "a_0", "when": "2018-04-07T01:17:21Z"}, {"anon": "stud", "data": "jfprungnvb0612", "to": "jfooun69vyq91", "type": "s_answer", "uid_a": "a_1", "when": "2018-04-07T19:28:06Z"}, {"anon": "stud", "to": "jfooun69vyq91", "type": "followup", "uid_a": "a_2", "when": "2018-04-09T17:27:13Z"}, {"anon": "stud", "to": "jfooun69vyq91", "type": "followup", "uid_a": "a_0", "when": "2018-04-10T05:29:35Z"}, {"anon": "stud", "to": "jfooun69vyq91", "type": "feedback", "uid_a": "a_0", "when": "2018-04-10T05:30:14Z"}], "children": [{"bucket_name": "Today", "bucket_order": 3, "children": [], "config": {}, "created": "2018-04-07T19:28:06Z", "data": {"embed_links": []}, "folders": [], "history": [{"anon": "stud", "content": "<p>Most likely this is due to a bottleneck in data input. You can use Tensorboard to get a profile of the performance.</p>\n<p></p>\n<p>What type of cell are you using?</p>", "created": "2018-04-07T19:28:06Z", "subject": "", "uid_a": "a_1"}], "id": "jfprunggfcz611", "is_tag_endorse": false, "tag_endorse": [{"admin": false, "endorser": {}, "facebook_id": null, "id": "i54fj8at4ryfv", "name": "Brandon Huang", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}], "tag_endorse_arr": ["i54fj8at4ryfv"], "type": "s_answer"}, {"anon": "stud", "bucket_name": "Week 4/8 - 4/14", "bucket_order": 111, "children": [{"anon": "stud", "bucket_name": "Week 4/8 - 4/14", "bucket_order": 111, "children": [], "config": {}, "created": "2018-04-10T05:30:14Z", "data": {"embed_links": null}, "folders": [], "id": "jft88owatoh674", "subject": "<p>Not sure which machines you were using but I just found virtualenv already installed on the machine.</p>", "tag_good": [], "tag_good_arr": [], "type": "feedback", "uid_a": "a_0", "updated": "2018-04-10T05:30:14Z"}], "config": {}, "created": "2018-04-09T17:27:13Z", "data": {"embed_links": null}, "folders": [], "id": "jfsievnccht1nc", "no_answer": 0, "no_upvotes": 0, "subject": "<p>As an aside how do you install tensorflow on the instructional machines? Last time I tried to do this I tried to\u00a0make a virtualenv but it wouldn&#39;t let me install virtualenv. I thought you couldn&#39;t install anything on instructional machines?</p>", "tag_good": [], "tag_good_arr": [], "type": "followup", "uid_a": "a_2", "updated": "2018-04-09T17:27:13Z"}, {"anon": "stud", "bucket_name": "Week 4/8 - 4/14", "bucket_order": 111, "children": [], "config": {}, "created": "2018-04-10T05:29:35Z", "data": {"embed_links": null}, "folders": [], "id": "jft87unlx1e5ot", "no_answer": 0, "no_upvotes": 0, "subject": "<p>OP here, we were doing attention models for machine translation. I guess that is somewhat hard to parallelize, huh. The paper we were basing it off of is the following:\u00a0<a href=\"https://arxiv.org/pdf/1409.0473.pdf\">https://arxiv.org/pdf/1409.0473.pdf</a></p>\n<p></p>\n<p>At the very least, since we were using a batch size around 32 or 64, shouldn&#39;t it be possible to parallelize across examples in the minibatch?</p>", "tag_good": [], "tag_good_arr": [], "type": "followup", "uid_a": "a_0", "updated": "2018-04-10T05:29:35Z"}], "config": {}, "created": "2018-04-07T01:16:21Z", "data": {"embed_links": []}, "default_anonymity": "no", "drafts": null, "folders": ["other"], "history": [{"anon": "stud", "content": "<p>I recently tried using Tensorflow to train some recurrent nets on the instructional machines. In particular, I was using hearst.cs.berkeley.edu which shows as having 8x Intel Xeon 4-core processors available for compute. I thought this would lead to a pretty massive speedup over my 2014 Macbook Pro, but I actually was only able to achieve the same training rate. Has anyone else run into issues with parallelizing CPU workloads on the instructional machines? What seems to happen is that all of the CPUs go from 0% usage to about 60% and stay there throughout the training process, which leads me to believe the workload might be duplicated, not distributed, over the processors.</p>\n<p></p>\n<p>I thought this might be a good place to ask this as I&#39;m sure there are plenty of people with experience programming on the instructional machines.</p>", "created": "2018-04-07T01:17:21Z", "subject": "training ML models using Tensorflow on the instructional machines- cpu parallelism", "uid_a": "a_0"}, {"anon": "stud", "content": "<p>I recently tried using Tensorflow to train some recurrent nets on the instructional machines. In particular, I was using hearst.cs.berkeley.edu which shows as having 8x Intel Xeon 4-core processors available for compute. I thought this would lead to a pretty massive speedup over my 2014 Macbook Pro, but I actually was only able to achieve the same training rate. Has anyone else run into issues with parallelizing CPU workloads on the instructional machines? What seems to happen is that all of the CPUs go from 0% usage to about 60% and stay there throughout the training process, which leads me to believe the workload might be duplicated, not distributed, over the processors.</p>", "created": "2018-04-07T01:16:21Z", "subject": "training ML models using Tensorflow on the instructional machines- cpu parallelism", "uid_a": "a_0"}], "i_edits": [], "id": "jfooun69vyq91", "is_bookmarked": false, "is_tag_good": false, "my_favorite": false, "no_answer": 0, "no_answer_followup": 0, "nr": 6514, "num_favorites": 2, "q_edits": [], "request_instructor": 0, "request_instructor_me": false, "s_edits": [], "status": "active", "t": 1654549870215, "tag_good": [], "tag_good_arr": [], "tags": ["other", "student"], "type": "question", "unique_views": 324}