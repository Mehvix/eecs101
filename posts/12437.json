{"bookmarked": 7, "bucket_name": "Today", "bucket_order": 3, "change_log": [{"anon": "stud", "data": "kb6rhw0u27j7h6", "type": "create", "uid_a": "a_0", "v": "all", "when": "2020-06-08T17:21:08Z"}, {"anon": "no", "data": "kb7h9cgbbhs6s3", "to": "kb6rhw0rpa7h5", "type": "s_answer", "uid": "iq1ocowl1xq6ia", "when": "2020-06-09T05:22:20Z"}, {"anon": "no", "data": "kb7hfg6ujuz599", "type": "s_answer_update", "uid": "iq1ocowl1xq6ia", "when": "2020-06-09T05:27:05Z"}, {"anon": "no", "data": "kb7ir4ablnw3tf", "type": "s_answer_update", "uid": "iq1ocowl1xq6ia", "when": "2020-06-09T06:04:09Z"}, {"anon": "no", "data": "kb7irhonro83zs", "type": "s_answer_update", "uid": "iq1ocowl1xq6ia", "when": "2020-06-09T06:04:26Z"}, {"anon": "no", "data": "kb7j8vcw4gm3z2", "type": "s_answer_update", "uid": "iq1ocowl1xq6ia", "when": "2020-06-09T06:17:57Z"}, {"anon": "no", "data": "kb7jlr8gosq27j", "type": "s_answer_update", "uid": "iq1ocowl1xq6ia", "when": "2020-06-09T06:27:58Z"}, {"anon": "no", "data": "kb7jmmdjgkg2vp", "type": "s_answer_update", "uid": "iq1ocowl1xq6ia", "when": "2020-06-09T06:28:38Z"}, {"anon": "no", "to": "kb6rhw0rpa7h5", "type": "followup", "uid": "is6p815tz306kj", "when": "2020-06-09T07:35:32Z"}, {"anon": "stud", "data": "kb7xwjn4h9u71n", "type": "s_answer_update", "uid_a": "a_1", "when": "2020-06-09T13:08:16Z"}, {"anon": "stud", "data": "kb7ynu15o7i40q", "type": "s_answer_update", "uid_a": "a_1", "when": "2020-06-09T13:29:29Z"}, {"anon": "stud", "data": "kb7yq0elqtdyn", "type": "s_answer_update", "uid_a": "a_1", "when": "2020-06-09T13:31:11Z"}, {"anon": "stud", "data": "kb7z2qarkmijk", "type": "s_answer_update", "uid_a": "a_1", "when": "2020-06-09T13:41:04Z"}, {"anon": "stud", "data": "kb8urgabiqf4vu", "type": "s_answer_update", "uid_a": "a_1", "when": "2020-06-10T04:28:06Z"}], "children": [{"bucket_name": "Today", "bucket_order": 3, "children": [], "config": {}, "created": "2020-06-09T05:22:20Z", "data": {"embed_links": []}, "folders": [], "history": [{"anon": "stud", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. Before taking 16A/B, I already knew most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed the flow of the two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and all the teaching staff of 16A/B are satisfied with the fact that they are able to reassemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc., but that does not define everything in those subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are nonlinear devices, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semesters left.) What I want to reveal is the fact that 16A/B only show you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. For example, a continuous signal can be thought of as a vector. Then, you can define the inner product using an integral and find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in the L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they were geared towards ML or digital signal processing, which is discrete and finite-dimensional; thus, you were not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for applying certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is the &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part. In terms of the actual content of EE140, I recommend reading <a href=\"/class/hyq0br1u3kx7dg?cid=11757\"></a><a href=\"/class/hyq0br1u3kx7dg?cid=11757\"></a><a href=\"/class/hyq0br1u3kx7dg?cid=11757\">@11757</a>.</p>", "created": "2020-06-10T04:28:06Z", "subject": "", "uid_a": "a_1"}, {"anon": "stud", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. Before taking 16A/B, I already knew most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed the flow of the two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and all the teaching staff of 16A/B are satisfied with the fact that they are able to reassemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc., but that does not define everything in those subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are nonlinear devices, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semesters left.) What I want to reveal is the fact that 16A/B only show you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. For example, a continuous signal can be thought of as a vector. Then, you can define the inner product using an integral and find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is the &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part. In terms of the actual content of EE140, I recommend reading <a href=\"https://piazza.com/class/hyq0br1u3kx7dg?cid=11757\"></a><a href=\"https://piazza.com/class/hyq0br1u3kx7dg?cid=11757\"></a><a href=\"https://piazza.com/class/hyq0br1u3kx7dg?cid=11757\">@11757</a>.</p>", "created": "2020-06-09T13:41:04Z", "subject": "", "uid_a": "a_1"}, {"anon": "stud", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. Before taking 16A/B, I already knew most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed the flow of the two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and all the teaching staff of 16A/B are satisfied with the fact that they are able to reassemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are nonlinear devices, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semesters left.) What I want to reveal is the fact that 16A/B only show you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. For example, a continuous signal can be thought of as a vector. Then, you can define the inner product using an integral and find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is the &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part. In terms of the actual content of EE140, I recommend reading <a href=\"https://piazza.com/class/hyq0br1u3kx7dg?cid=11757\"></a><a href=\"https://piazza.com/class/hyq0br1u3kx7dg?cid=11757\">@11757</a>.</p>", "created": "2020-06-09T13:31:11Z", "subject": "", "uid_a": "a_1"}, {"anon": "stud", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. Before taking 16A/B, I already knew most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed the flow of the two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and all the teaching staff of 16A/B are satisfied with the fact that they are able to reassemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are nonlinear devices, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semesters left.) What I want to reveal is the fact that 16A/B only shows you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. For example, a continuous signal can be thought of as a vector. Then, you can define the inner product using an integral and find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is the &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part. In terms of the actual content of EE140, I recommend reading <a href=\"https://piazza.com/class/hyq0br1u3kx7dg?cid=11757\">@11757</a>.</p>", "created": "2020-06-09T13:29:29Z", "subject": "", "uid_a": "a_1"}, {"anon": "stud", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. I came to 16A/16B knowing most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed these two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and the teaching staff of 16A/B shared a similar sentiment about how successfully 16A/B can assemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are nonlinear devices, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semesters left.) What I want to reveal is the fact that 16A/B only shows you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. For example, a continuous signal can be thought of as a vector. Then, you can define the inner product using an integral and find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is the &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part. In terms of the actual content of EE140, I recommend reading @11757.</p>", "created": "2020-06-09T13:08:16Z", "subject": "", "uid_a": "a_1"}, {"anon": "no", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. I came to 16A/16B knowing most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed these two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and the teaching staff of 16A/B shared a similar sentiment about how successfully 16A/B can assemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are nonlinear devices, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semesters left.) What I want to reveal is the fact that 16A/B only shows you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. A continuous signal can be though as a signal. You can define an inner product using an integral, and you can find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is the &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part. In terms of the actual content of EE140, I recommend reading @11757.</p>", "created": "2020-06-09T06:28:38Z", "subject": "", "uid": "iq1ocowl1xq6ia"}, {"anon": "no", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. I came to 16A/16B knowing most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed these two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and the teaching staff of 16A/B shared a similar sentiment about how successfully 16A/B can assemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are nonlinear devices, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semester left.) What I want to reveal is the fact that 16A/B only shows you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. A continuous signal can be though as a signal. You can define an inner product using an integral, and you can find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is the &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part. In terms of the actual content of EE140, I recommend reading @11757.</p>", "created": "2020-06-09T06:27:58Z", "subject": "", "uid": "iq1ocowl1xq6ia"}, {"anon": "no", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. I came to 16A/16B knowing most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed these two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and the teaching staff of 16A/B shared a similar sentiment about how successfully 16A/B can assemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are a nonlinear device, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semester left.) What I want to reveal is the fact that 16A/B only shows you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. A continuous signal can be though as a signal. You can define an inner product using an integral, and you can find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is the &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part. In terms of the actual content of EE140, I recommend reading @11757.</p>", "created": "2020-06-09T06:17:57Z", "subject": "", "uid": "iq1ocowl1xq6ia"}, {"anon": "no", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. I came to 16A/16B knowing most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed these two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and the teaching staff of 16A/B shared a similar sentiment about how successfully 16A/B can assemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are a nonlinear device, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semester left.) What I want to reveal is the fact that 16A/B only shows you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. A continuous signal can be though as a signal. You can define an inner product using an integral, and you can find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is the &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part.</p>", "created": "2020-06-09T06:04:26Z", "subject": "", "uid": "iq1ocowl1xq6ia"}, {"anon": "no", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. I came to 16A/16B knowing most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed these two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and the teaching staff of 16A/B shared a similar sentiment about how successfully 16A/B can assemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are a nonlinear device, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semester left.) What I want to reveal is the fact that 16A/B only shows you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. A continuous signal can be though as a signal. You can define an inner product using an integral, and you can find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>\n<p></p>\n<p>EDIT: I should also mention the abstraction used in circuits. The first principle you learned in CS61A is an &#34;abstraction barrier&#34;, which is usually a word used in contrast with the hardware world. Surprisingly, hardware designers by heart rely on abstraction in all possible ways. For example, a highly nonlinear 5-transistor differential amplifier can be abstracted into a two-port model using Taylor expansion, allowing designers to concatenate two complicated systems in a way that is as simple as multiplying two matrices. I am sure people who are used to programming will like that part.</p>", "created": "2020-06-09T06:04:09Z", "subject": "", "uid": "iq1ocowl1xq6ia"}, {"anon": "no", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. I came to 16A/16B knowing most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed these two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and the teaching staff of 16A/B shared a similar sentiment about how successfully 16A/B can assemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are a nonlinear device, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semester left.) What I want to reveal is the fact that 16A/B only shows you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. A continuous signal can be though as a signal. You can define an inner product using an integral, and you can find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is symmetric positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>", "created": "2020-06-09T05:27:05Z", "subject": "", "uid": "iq1ocowl1xq6ia"}, {"anon": "no", "content": "<p>Before discussing why the circuit theory and the field of EE are inspiring to learn, we should all agree that SWE provides better financial outcomes, at least in the short term. You will definitely make a good living as an IC designer, but probably not as glamorous as your CS peers. Another point worth mentioning is that you generally need to have a higher degree to start your career. Although some of my professors said that being a Berkeley undergrad is sufficient, in reality, it&#39;s probably better to have at least an MS.\u00a0</p>\n<p></p>\n<p>Although I&#39;m now kind of against linear algebra, I definitely was a &#34;linear-algebra&#34; person initially. I took Math 54/110 and EE16A/B/127/221A, which almost led me to the belief that everything can be cast into linear algebra. I came to 16A/16B knowing most of the stuff, such as differential equations, Fourier transforms, system theory, so I actually enjoyed these two classes. I liked how everything was intertwined and how linear algebra was shown to be the fundamental building block of all the concepts presented in 16A/B. In fact, I have talked to several professors who were not happy about the creation of 16A/B, from whom I also realized that there was another subset of the faculties, really pushing the integration of linear algebra into the lower divs. I am sure those faculties and the teaching staff of 16A/B shared a similar sentiment about how successfully 16A/B can assemble different subfields of EE into just two classes.\u00a0</p>\n<p></p>\n<p>HOWEVER, if you are students who have no background in EE, then EE16A/B are quite misleading, both philosophically and mathematically. First, subfields of EE are not that seamlessly related. You will indeed see linear algebra appears in control, signal processing, analog circuits, optoelectronics, etc.; however, that does not define everything in the subfields. You probably are used to the idea of linearizing a system around an equilibrium point and use negative feedback to move the eigenvalues; you probably are told not to rail out your op-amp. But the reality is that people also rely on nonlinear behaviors and positive feedback to stabilize the circuit, which is sometimes more robust than a linearized circuit. Transistors are a nonlinear device, so it doesn&#39;t make sense to just use them approximately. (There are so many other examples in control where nonlinear feedback is used; I recommend EE222 for people who have more semester left.) What I want to reveal is the fact that 16A/B only shows you the linear algebra perspective, which tbh is still powerful but oversimplifies the rich development in EE.\u00a0</p>\n<p></p>\n<p>Second, in terms of linear algebra, the course is also too &#34;concrete&#34;. The linear algebra you were taught is about matrices. In 16A/B and even in 127, a linear transformation is a matrix, which is true in a finite-dimensional space. The most powerful idea in EE is probably Fourier and Laplace transform, which is intrinsically linear-algebraic and used in one way or another in every subfield of EE (analog designers rely on the idea of the frequency response of a circuit; control community use Laplace transform to understand the stability of the system; device people uses Fourier transform to explore the k-space of a solid). However, to understand the frequency domain, one must reach a new level of understanding towards vectors and operators. A continuous signal can be though as a signal. You can define an inner product using an integral, and you can find eigenvalues of an abstract system. This appears in 16B but is clearly not emphasized. For example, you can treat differentiation as an operator; given certain boundary conditions, you can find the eigenvectors of a differential operator, which in 16B is $$e^{\\lambda t}$$. Not many people coming out of 16B knew that the gradient operator is anti-symmetric in L2 vector space, and the divergence of the gradient operator is a positive-definite. You learned useful linear algebra tricks from 16B, but they are gear towards ML or signal processing, which is discrete and finite-dimensional; thus, you are not trained to think linear algebra more abstractly. As I said before, linear algebra is used frequently in EE, but not all subfields use it computationally. For people doing optimization algorithms, they do care about actual matrix manipulation; however, for circuit designers, linear algebra is used more as a justification for using certain design principles.</p>\n<p></p>\n<p>Another point I want to bring up is the idea of &#34;engineering&#34;, which, personally, I equate it with the word &#34;trade-off&#34;. Engineering relies on physics and math; nevertheless, it differentiates itself from science because problems are usually constrained. ML and control make optimization looks like a mathematical trick; however, recall that 127 is used to be an EE course where the primary goal is to find an optimal solution given a set of design constraints. (The main concept of optimization originated from Lagrangian and Hamiltonian physics, where the dynamics of the physical system is treated as the constraint, so the original idea was indeed more as a mathematical trick.) In hardware design, let it be electronic, mechanical, or optical, you are always constrained by cost, bandwidth, power, noise, etc. For me, that&#39;s the most fascinating and valuable part of learning circuits and other subfields of EE.\u00a0</p>", "created": "2020-06-09T05:22:20Z", "subject": "", "uid": "iq1ocowl1xq6ia"}], "history_size": 12, "id": "kb7h9cg0qif6s2", "is_tag_endorse": false, "tag_endorse": [{"admin": false, "endorser": {}, "facebook_id": null, "id": "is6p815tz306kj", "name": "Averal Kandala", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {"global": 1568151855, "irdpgxf12pr3t1": 1, "jkj72dhu5xf7my": 1541360409, "jyz1vzhx2on2wq": 1568088917, "jzapntwvv074c9": 1569885082, "jzllv02dp7j3jh": 1568151855, "kb74zdsef1y42h": 1597086076}, "facebook_id": null, "id": "iq1ocowl1xq6ia", "name": "Kerry Yu", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {}, "facebook_id": null, "id": "jktvex6279x3zb", "name": "Maxwell Chen", "photo": "1579165146_200.jpg", "photo_url": "https://cdn-uploads.piazza.com/photos/jktvex6279x3zb/1579165146_200.jpg", "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {"k05lwuecp024ee": 1576634790}, "facebook_id": null, "id": "jzhgim9yiq3or", "name": "Zhimeng Wang", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {"jr9vegl92h23af": 1554184636, "kk3eqam1ck45i8": 1613978433}, "facebook_id": null, "id": "j6obyk9djd83l5", "name": "Estella Chen", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {"jyq487ctcwuk8": 1570760427}, "facebook_id": null, "id": "jzccssa5qo462l", "name": "Hari Vallabhaneni", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {}, "facebook_id": null, "id": "is6p9mf96y2ty", "name": "Henry Muller", "photo": "1484632252_35.png", "photo_url": "https://cdn-uploads.piazza.com/photos/is6p9mf96y2ty/1484632252_35.png", "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {"jpslgn3m4lsk6": 1555223627, "ke0mwss5bxj4hs": 1600242896}, "facebook_id": null, "id": "jhobhold1yokb", "name": "Kaushik Sankar", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {}, "facebook_id": null, "id": "jgpxo884ib12yq", "name": "Yizhuo Miao", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {"global": 1535223700, "hyq0br1u3kx7dg": 1525795138, "j5zp8esecm31rr": 1, "j7s01y165odq5": 1515461097, "j9j0udrxjjp758": 1519242790, "jjd5ukm1ddp6x6": 1535223700, "jkopvsyuy7g3u0": 1535681645}, "facebook_id": null, "id": "j1hge0e6rt9yo", "name": "Alex Kassil", "photo": "1525041329_35.png", "photo_url": "https://cdn-uploads.piazza.com/photos/j1hge0e6rt9yo/1525041329_35.png", "published": true, "role": "student", "us": false}], "tag_endorse_arr": ["is6p815tz306kj", "iq1ocowl1xq6ia", "jktvex6279x3zb", "jzhgim9yiq3or", "j6obyk9djd83l5", "jzccssa5qo462l", "is6p9mf96y2ty", "jhobhold1yokb", "jgpxo884ib12yq", "j1hge0e6rt9yo"], "type": "s_answer"}, {"anon": "no", "bucket_name": "Week 6/7 - 6/13", "bucket_order": 44, "children": [], "config": {}, "created": "2020-06-09T07:35:32Z", "data": {"embed_links": null}, "folders": [], "id": "kb7m0nlnant7fh", "no_answer": 0, "no_upvotes": 0, "subject": "<p>I&#39;ve spoken to at least one grad student that has taken 240A (the graduate version of 140, which includes just a little more work on the exams and project) without a significant background in circuits (read: equivalent of EE 105 at their undergrad university), so it&#39;s certainly possible to just &#34;jump in&#34; with the right level of maturity. As Kerry pointed out, however, the EE 16AB series is uniquely bad in the sense that it gives students the impression that most of EE can be abstracted away as a number of constrained optimization / inference problems. In such problems, you would place the relevant parameters in the computational harness of linear algebra and allow a computer to do your &#34;design&#34; and/or analysis for you.\u00a0</p>\n<p></p>\n<p>Circuit design is so interesting precisely because, within a given design space, you -- the designer --\u00a0 make choices that determine the operation of the system that uses the circuit (circuit design is never an end-all, be-all), and many different choices of parameters can be &#34;optimal&#34; within this space. In this sense, a circuit design could never be &#34;auto-graded&#34; outside of its basic operation (admittedly, just getting the thing to work is hard enough in most cases).\u00a0</p>\n<p></p>\n<p>As for takeaways from 140, you should understand how to design an amplifier (for a number of specific contexts) and evaluate its stability in the almost certain case that it is placed in negative feedback (for reasons that you will be able to explain). One practical skill that I didn&#39;t develop until after 140, but you can certainly plan to incorporate into your learning, is that of converting design equations into a script that tells you how to design your circuit. The art here is knowing which equations take precedence in the design process (which 140 should teach you, and 240B spends a lot of time building on further). Additionally, designing generalized testbenches to accurately characterize the devices you use in your circuits is necessary when using more advanced (short-channel) processes. In Prof. Pister&#39;s iterations of 140, students are allowed to use devices with incredibly long channels by the standards of today&#39;s technologies, which allows students to directly apply equations from class to &#34;solve&#34; their design. In Prof. Muller&#39;s iterations, students are forced to use a 45 nm process, which doesn&#39;t allow this.</p>\n<p></p>\n<p>If you&#39;d like to learn more after 140, I&#39;d recommend watching the Spring 2010 webcasts of EE 240, taught by Prof. Alon. The literal tens of thousands of views of these videos from before Cal was sued for ADA noncompliance are testament to the quality of the teaching that semester.\u00a0\u00a0</p>", "tag_good": [{"admin": false, "endorser": {"global": 1568151855, "irdpgxf12pr3t1": 1, "jkj72dhu5xf7my": 1541360409, "jyz1vzhx2on2wq": 1568088917, "jzapntwvv074c9": 1569885082, "jzllv02dp7j3jh": 1568151855, "kb74zdsef1y42h": 1597086076}, "facebook_id": null, "id": "iq1ocowl1xq6ia", "name": "Kerry Yu", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {"jyq487ctcwuk8": 1570760427}, "facebook_id": null, "id": "jzccssa5qo462l", "name": "Hari Vallabhaneni", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {"jpslgn3m4lsk6": 1555223627, "ke0mwss5bxj4hs": 1600242896}, "facebook_id": null, "id": "jhobhold1yokb", "name": "Kaushik Sankar", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {}, "facebook_id": null, "id": "is6p9mf96y2ty", "name": "Henry Muller", "photo": "1484632252_35.png", "photo_url": "https://cdn-uploads.piazza.com/photos/is6p9mf96y2ty/1484632252_35.png", "published": true, "role": "student", "us": false}], "tag_good_arr": ["iq1ocowl1xq6ia", "jzccssa5qo462l", "jhobhold1yokb", "is6p9mf96y2ty"], "type": "followup", "uid": "is6p815tz306kj", "updated": "2020-06-09T07:35:32Z"}], "config": {"seen": {"10399": 4, "11076": 3, "11402": 0, "12307": 7, "5201": 6, "5601": 8, "8343": 1, "9002": 9, "9312": 2, "9831": 5}}, "created": "2020-06-08T17:21:08Z", "data": {"embed_links": []}, "default_anonymity": "no", "drafts": null, "folders": ["other"], "history": [{"anon": "stud", "content": "<p>I have one more semester left at Cal and it seems that 140 will strictly be offered next semester (was considering taking a semester off then coming back).\u00a0</p>\n<p></p>\n<p>I haven&#39;t taken 105 and plan to self-study it this summer. I can PNP all my classes next semester so I&#39;m not incredibly stressed about getting a great grade in 140--I just want to learn as much as possible.</p>\n<p></p>\n<p>16a/16b didn&#39;t really emphasize why we learned anything about circuits, and I&#39;m curious why someone might want to take 105 and 140. Why ML and general SWE is important is beat to death, but we never really got much insight on why we ought to be excited about circuits. Might someone want to shed light on what the learning outcomes for 140 would be like?</p>", "created": "2020-06-08T17:21:08Z", "subject": "EE140 questions", "uid_a": "a_0"}], "history_size": 1, "i_edits": [], "id": "kb6rhw0rpa7h5", "is_bookmarked": false, "is_tag_good": false, "my_favorite": false, "no_answer": 0, "no_answer_followup": 0, "nr": 12437, "num_favorites": 6, "q_edits": [], "request_instructor": 0, "request_instructor_me": false, "s_edits": [], "status": "active", "t": 1654543330694, "tag_good": [{"admin": false, "endorser": {"global": 1568151855, "irdpgxf12pr3t1": 1, "jkj72dhu5xf7my": 1541360409, "jyz1vzhx2on2wq": 1568088917, "jzapntwvv074c9": 1569885082, "jzllv02dp7j3jh": 1568151855, "kb74zdsef1y42h": 1597086076}, "facebook_id": null, "id": "iq1ocowl1xq6ia", "name": "Kerry Yu", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}, {"admin": false, "endorser": {}, "facebook_id": null, "id": "is6p9mf96y2ty", "name": "Henry Muller", "photo": "1484632252_35.png", "photo_url": "https://cdn-uploads.piazza.com/photos/is6p9mf96y2ty/1484632252_35.png", "published": true, "role": "student", "us": false}], "tag_good_arr": ["iq1ocowl1xq6ia", "is6p9mf96y2ty"], "tags": ["other", "student"], "type": "question", "unique_views": 308}