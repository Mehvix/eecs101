{"bookmarked": 5, "bucket_name": "Today", "bucket_order": 3, "change_log": [{"anon": "no", "data": "jkmq6y4g7l2pq", "type": "create", "uid": "gxj8rtteeuaa9", "when": "2018-08-09T15:36:54Z"}, {"anon": "no", "data": "jkmqx6hmogg6ye", "type": "update", "uid": "gxj8rtteeuaa9", "when": "2018-08-09T15:57:18Z"}, {"anon": "stud", "to": "jkmq6y4fk1qpp", "type": "followup", "uid_a": "a_0", "when": "2018-08-09T17:21:35Z"}, {"anon": "no", "to": "jkmq6y4fk1qpp", "type": "feedback", "uid": "gxj8rtteeuaa9", "when": "2018-08-09T18:37:12Z"}, {"anon": "no", "to": "jkmq6y4fk1qpp", "type": "followup", "uid": "gxj8rtteeuaa9", "when": "2018-08-12T21:15:30Z"}, {"anon": "stud", "to": "jkmq6y4fk1qpp", "type": "followup", "uid_a": "a_1", "when": "2018-08-15T18:15:57Z"}, {"anon": "no", "to": "jkmq6y4fk1qpp", "type": "feedback", "uid": "j1hge0e6rt9yo", "when": "2018-08-15T21:49:16Z"}], "children": [{"anon": "stud", "bucket_name": "Week 8/5 - 8/11", "bucket_order": 88, "children": [{"anon": "no", "bucket_name": "Week 8/5 - 8/11", "bucket_order": 88, "children": [], "config": {}, "created": "2018-08-09T18:37:12Z", "data": {"embed_links": null}, "folders": [], "id": "jkmwmt6s83151t", "subject": "<p>There might be notes available at the end of the semester. This is a special topics course --- we&#39;re building it as we go. Figuring out how to teach this material in a way that is accessible while getting to the essential core.</p>\n<p></p>\n<p>The team projects are going to be things that teams of students propose to do that engage with the material that we are covering. Here, connecting to some application (find and propose one) is going to be highly encouraged, but selected theoretically motivated projects are also going to be allowed.</p>\n<p></p>\n<p></p>", "tag_good": [], "tag_good_arr": [], "type": "feedback", "uid": "gxj8rtteeuaa9", "updated": "2018-08-09T18:37:12Z"}], "config": {}, "created": "2018-08-09T17:21:35Z", "data": {"embed_links": null}, "folders": [], "id": "jkmtxkp2o512tb", "no_answer": 0, "no_upvotes": 0, "subject": "<p>Is there a set of notes available for reading? and possibly what the team project is about?</p>", "tag_good": [], "tag_good_arr": [], "type": "followup", "uid_a": "a_0", "updated": "2018-08-09T17:21:35Z"}, {"anon": "no", "bucket_name": "Week 8/12 - 8/18", "bucket_order": 87, "children": [], "config": {}, "created": "2018-08-12T21:15:30Z", "data": {"embed_links": null}, "folders": [], "id": "jkrclxophrd5uw", "no_answer": 0, "no_upvotes": 0, "subject": "<p>Follow up: interested undergrads should feel free to add themselves to the waitlist. I expect that there will be some normal amount of attrition in the course, and if necessary, we will rebalance the enrollment across the grad and undergrad sections of the course as long as we stay under the room capacity of 98 students. It is not hopeless to get in.\u00a0</p>\n<p></p>\n<p>I have gotten questions regarding the workload. There is not going to be the quantity of homework that exists in a course like 189. i.e. We expect to have significantly shorter homework sets. However, student groups will also take turns working with us to *make* problems and/or demos for their peers --- so these can be viewed as intensive short projects where you get some say in the deadline. Students will also be expected to take turns scribing lecture, and revising the resulting notes in light of feedback, etc. These are also little bursts of effort, where you get some say in scheduling those bursts. The group/team projects are expected to be substantial, with that workload falling largely at the end of the term. Students are permitted (even encouraged in some cases) to explore synergies between their research projects or projects in other courses and the project for this course. Ideally, we&#39;d like to see many of these projects turn into the seeds for publishable papers.</p>\n<p></p>\n<p>All of this means that this is a course for students who want to really understand the concepts that we are teaching. For this, being comfortable with probabilistic arguments is going to be important --- that&#39;s why the strong emphasis on knowing probability at least at the level of 126. A level of maturity is also going to be expected --- at times, you&#39;ll be expected to read and digest material from primary papers in the area. We and your peers will help, of course, but you&#39;re going to have to be willing to do the work. Optimization ideas are going to work themselves in along the way --- how could they not in a course about learning --- so that is why we are saying either 127 or 189 level understanding is important. When it comes to 189 material itself, we will be doing a super fast 189-in-a-nutshell treatment at the beginning to make sure that folks without it can engage if they have the right level of maturity.\u00a0</p>\n<p></p>\n<p></p>\n<p></p>", "tag_good": [], "tag_good_arr": [], "type": "followup", "uid": "gxj8rtteeuaa9", "updated": "2018-08-12T21:15:30Z"}, {"anon": "stud", "bucket_name": "Week 8/12 - 8/18", "bucket_order": 87, "children": [{"anon": "no", "bucket_name": "Week 8/12 - 8/18", "bucket_order": 87, "children": [], "config": {}, "created": "2018-08-15T21:49:16Z", "data": {"embed_links": null}, "folders": [], "id": "jkvo4xdk8un3bu", "subject": "<p>Look at the follow up above!</p>", "tag_good": [], "tag_good_arr": [], "type": "feedback", "uid": "j1hge0e6rt9yo", "updated": "2018-08-15T21:49:16Z"}], "config": {}, "created": "2018-08-15T18:15:57Z", "data": {"embed_links": null}, "folders": [], "id": "jkvgilovkxd4ay", "no_answer": 0, "no_upvotes": 0, "subject": "<p>Hi Professor Sahai</p>\n<p></p>\n<p>Will there be some form of notes/textbook that we can follow (at least for some of the concepts)?\u00a0</p>", "tag_good": [], "tag_good_arr": [], "type": "followup", "uid_a": "a_1", "updated": "2018-08-15T18:15:57Z"}], "config": {}, "created": "2018-08-09T15:36:54Z", "data": {"embed_links": []}, "default_anonymity": "no", "drafts": null, "folders": ["other", "announcements"], "history": [{"anon": "no", "content": "<p>EE290S/EE194 -\u00a0Machine learning for sequential decision making under uncertainty</p>\n<div>Class number:\u00a034087 (EE194 for advanced undergrads), 27811 (EE290S for graduate students)</div>\n<div>TuTh 2-3:30pm, 306 Soda</div>\n<div>Instructors: Anant Sahai and Vidya Muthukumar</div>\n<div></div>\n<div></div>\n<div>\n<p dir=\"ltr\">This course is about learning to make decisions that are embedded in time and in an uncertain environment. What does it even mean to do well in such settings and how can we evaluate performance? What if we do not fully trust a probabilistic model? What if there are game-theoretic or adversarial aspects? How can we intelligently navigate the tension between exploration (figuring out what is going on), exploitation (reaping the rewards of what we have learned), and defense (preventing a potentially adversarial environment from exploiting us!)? How does this change if our feedback from the environment is delayed or sparse?</p>\n<p dir=\"ltr\"></p>\n<p dir=\"ltr\">This course will engage at both the conceptual and technical (mathematical) levels. Projects and HWs are encouraged to also engage with applications.</p>\n<p dir=\"ltr\"></p>\n<p dir=\"ltr\"><strong>Grading: </strong></p>\n<ul><li>\n<p dir=\"ltr\">40% Team Project</p>\n</li><li>\n<p dir=\"ltr\">20% (Solo) Midterm</p>\n</li><li>\n<p dir=\"ltr\">15% Team HW (every two weeks)</p>\n</li><li>\n<p dir=\"ltr\">25% Participation (this includes scribing notes as well as making HW/Demos engaging with ideas covered.)</p>\n</li></ul>\n<p dir=\"ltr\"></p>\n<p dir=\"ltr\"><strong>Prerequisites:</strong> This course is intended for students who have had EECS 126 level probability *and* either EECS 127 (optimization) or CS 189 (machine learning). A basic undergraduate-level understanding of algorithms will also be assumed, along with mathematical maturity commensurate with students at this level.</p>\n<br />\n<p dir=\"ltr\"><strong>Rough technical outline</strong> (we will adapt in an online fashion based on course feedback)<strong>:</strong></p>\n<ul><li>\n<p>Introduction and traditional statistical ML in a nutshell</p>\n</li><li>\n<p>Introduction to sequential decision making</p>\n</li><li>\n<p>Adversarial environments, games, and learning within them to minimize regret</p>\n</li><li>\n<p>The need for randomization, exponential weights, and understanding mirror descent in the context of regularization.</p>\n</li><li>\n<p>Adaptation, the exploration/exploitation tradeoff, and multi-arm bandits.</p>\n</li><li>\n<p>Contextual bandits and reinforcement learning</p>\n</li></ul>\n</div>", "created": "2018-08-09T15:57:18Z", "subject": "F18: Special topics 194/290S - Machine learning for sequential decision making under uncertainty", "uid": "gxj8rtteeuaa9"}, {"anon": "no", "content": "<p>EE290S/EE194 -\u00a0Machine learning for sequential decision making under uncertainty</p>\n<div>Class number:\u00a034087 (EE194 for advanced undergrads), 27811 (EE290S for graduate students)</div>\n<div>TuTh 2-3:30pm, 306 Soda</div>\n<div>Instructors: Anant Sahai and Vidya Muthukumar</div>\n<div></div>\n<div>\n<p dir=\"ltr\">This course is about learning to make decisions that are embedded in time and in an uncertain environment. What does it even mean to do well in such settings and how can we evaluate performance? What if we do not fully trust a probabilistic model? What if there are game-theoretic or adversarial aspects? How can we intelligently navigate the tension between exploration (figuring out what is going on), exploitation (reaping the rewards of what we have learned), and defense (preventing a potentially adversarial environment from exploiting us!)? How does this change if our feedback from the environment is delayed or sparse?</p>\n<p dir=\"ltr\"></p>\n<p dir=\"ltr\"> </p>\n<p dir=\"ltr\">This course will engage at both the conceptual and technical (mathematical) levels. Projects and HWs are encouraged to also engage with applications.</p>\n<p dir=\"ltr\"></p>\n<p dir=\"ltr\"><strong>Grading: </strong></p>\n<ul><li>\n<p dir=\"ltr\">40% Team Project</p>\n</li><li>\n<p dir=\"ltr\">20% (Solo) Midterm</p>\n</li><li>\n<p dir=\"ltr\">15% Team HW (every two weeks)</p>\n</li><li>\n<p dir=\"ltr\">25% Participation (this includes scribing notes as well as making HW/Demos engaging with ideas covered.)</p>\n</li></ul>\n<p dir=\"ltr\"></p>\n<p dir=\"ltr\"><strong>Prerequisites:</strong> This course is intended for students who have had EECS 126 level probability *and* either EECS 127 (optimization) or CS 189 (machine learning). A basic undergraduate-level understanding of algorithms will also be assumed, along with mathematical maturity commensurate with students at this level. </p>\n<br />\n<p dir=\"ltr\"><strong>Rough technical outline</strong> (we will adapt in an online fashion based on course feedback)<strong>:</strong></p>\n<ul><li>\n<p>Introduction and traditional statistical ML in a nutshell</p>\n</li><li>\n<p>Introduction to sequential decision making</p>\n</li><li>\n<p>Adversarial environments, games, and learning within them to minimize regret</p>\n</li><li>\n<p>The need for randomization, exponential weights, and understanding mirror descent in the context of regularization.</p>\n</li><li>\n<p>Adaptation, the exploration/exploitation tradeoff, and multi-arm bandits.</p>\n</li><li>\n<p>Contextual bandits and reinforcement learning</p>\n</li></ul>\n</div>", "created": "2018-08-09T15:36:54Z", "subject": "F18: Special topics 194/290S - Machine learning for sequential decision making under uncertainty", "uid": "gxj8rtteeuaa9"}], "i_edits": [], "id": "jkmq6y4fk1qpp", "is_bookmarked": false, "is_tag_good": false, "my_favorite": false, "no_answer_followup": 0, "nr": 7402, "num_favorites": 2, "q_edits": [], "request_instructor": 0, "request_instructor_me": false, "s_edits": [], "status": "active", "t": 1654548850912, "tag_good": [], "tag_good_arr": [], "tags": ["announcements", "instructor-note", "other"], "type": "note", "unique_views": 598}