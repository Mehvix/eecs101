{"bookmarked": 8, "bucket_name": "Today", "bucket_order": 3, "change_log": [{"anon": "stud", "data": "l1e46xyhnl84yn", "type": "create", "uid_a": "a_0", "v": "all", "when": "2022-03-30T22:03:17Z"}], "children": [], "config": {"editor": "md", "has_emails_sent": 1}, "created": "2022-03-30T22:03:17Z", "data": {"embed_links": []}, "default_anonymity": "no", "drafts": null, "folders": ["peer_directed", "enrichment_opportunities", "other"], "history": [{"anon": "stud", "content": "<md>Hello everybody! I\u2019m a part of a student group on campus called\u00a0[Effective Altruism at Berkeley](https://eaberkeley.com/). We are\u00a0**hosting a contest that poses a technical and philosophical question about artificial intelligence**\u00a0and encourage you to participate!\n\nThe Artificial Intelligence Misalignment Solutions (AIMS) contest presents a scenario: Imagine that there is an advanced AI that you are training, which is rewarded for successfully guarding a diamond from being stolen. Since the AI is so advanced, it can be easier to trick people into believing that the AI has stopped the diamond from being taken than it is for the AI to actually protect the diamond. In other words, the AI is incentivized to trick you. How do we ensure that an AI accurately reports its actions and predictions of the future?\n\nThe AIMS contest was created in order to provide UC Berkeley students with a tangible opportunity to engage with the\u00a0[Alignment Problem](https://bdtechtalks.com/2021/01/18/ai-alignment-problem-brian-christian/). The Alignment Problem aims to ensure that AI produces outcomes that reflect our intentions and values. The ongoing advances in AI could lead to extremely positive developments, presenting solutions to now-intractable global problems, but they also pose severe risks, which is why the effective altruism community considers alignment one of the most pressing problems to work on.\n\nThis contest opened on our\u00a0[website](https://eaberkeley.com/aims-contest)\u00a0and submissions are due on April 12th, with more details in our\u00a0[contest description document](https://docs.google.com/document/d/1ZK3zrb5ah5Qy43HLLNpZVA19M5wsU1903MbjcQedR2A/edit?usp=sharing)! If you're interested, please fill out our [interest form](https://airtable.com/shrQzha77sUIf2vyz). We are offering a $500 first place prize, a $300 second place prize, and 20 $20 prizes for the first 20 submissions that suggest a new idea or improvement to the problem (as outlined in our contest description). (Note: we are in the process of doubling our prizes.)\n\nIf you have any questions, please feel free to email [admin@eaberkeley.com](mailto:admin@eaberkeley.com).<a href=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fkdzjqc0j7uz51m%2F8fe5fa50a04ba766f9dc3eb551e08b1015b1620afe32487375cb6130732a7b98%2FAIMS_flyer_description.jpeg\" target=\"_blank\" rel=\"noopener\"></a>\n<a href=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fkdzjqc0j7uz51m%2F8fe5fa50a04ba766f9dc3eb551e08b1015b1620afe32487375cb6130732a7b98%2FAIMS_flyer_description.jpeg\" target=\"_blank\" rel=\"noopener\"><img src=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fkdzjqc0j7uz51m%2Fa59dde21ab2ad5d0a26e47dea91239796cc78f02c7f1e55b354ec90eb9021090%2FAIMS_flyer_main.jpeg\" width=\"793\" height=\"1122\" alt=\"\" /></a>\n\n<a href=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fkdzjqc0j7uz51m%2F8fe5fa50a04ba766f9dc3eb551e08b1015b1620afe32487375cb6130732a7b98%2FAIMS_flyer_description.jpeg\" target=\"_blank\" rel=\"noopener\"><img src=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fkdzjqc0j7uz51m%2F8fe5fa50a04ba766f9dc3eb551e08b1015b1620afe32487375cb6130732a7b98%2FAIMS_flyer_description.jpeg\" width=\"400\" height=\"1000\" alt=\"\" /></a></md>", "created": "2022-03-30T22:03:17Z", "subject": "The Artificial Intelligence Misalignment Solutions (AIMS) contest", "uid_a": "a_0"}], "history_size": 1, "i_edits": [], "id": "l1e46xydfga4ym", "is_bookmarked": false, "is_tag_good": false, "my_favorite": false, "no_answer_followup": 0, "nr": 16690, "num_favorites": 0, "q_edits": [], "request_instructor": 0, "request_instructor_me": false, "s_edits": [], "status": "active", "t": 1654538646167, "tag_good": [{"admin": false, "endorser": {"global": 1581210147, "jziyku5gomy7aq": 1576285183, "k0g9j3r04edcn": 1575391697, "k5eevxebzpj25b": 1579570570, "k5g56y7yegw5xr": 1581284108, "k5mvapjoenll2": 1586565748, "k5qacftvzwp155": 1585607475, "kdz4wzqnb6052o": 1603637279, "ke609ylh5ap5uv": 1603222682, "kxj8vcku7037li": 1647206540}, "facebook_id": null, "id": "jy1rz92rpon1wh", "name": "Akshit Dewan", "photo": null, "photo_url": null, "published": true, "role": "student", "us": false}], "tag_good_arr": ["jy1rz92rpon1wh"], "tags": ["enrichment_opportunities", "other", "peer_directed", "student"], "type": "note", "unique_views": 377}